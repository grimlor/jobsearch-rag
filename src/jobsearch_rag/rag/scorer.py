"""Semantic scoring and LLM disqualifier classification.

The Scorer bridges two RAG concerns:

1. **Semantic similarity** — embed the JD text, query VectorStore collections
   (resume, role_archetypes, decisions) and convert cosine distances to
   similarity scores in [0.0, 1.0].

2. **LLM disqualification** — send a structured prompt to the Embedder's
   ``classify()`` method asking the LLM whether the role is structurally
   unsuitable (e.g. IC-disguised-as-architect, SRE on-call ownership,
   staffing agency chain).  The response is expected as JSON; malformed
   responses fall back to *not disqualified* (safe default).

ChromaDB returns *distances* (cosine distance = 1 - cosine_similarity).
The ``_distance_to_score`` helper converts the closest distance to a
similarity score clamped to [0.0, 1.0].

Long JDs are **chunked** before embedding so that no information is lost.
Real-world JDs frequently place comp ranges and hands-on responsibilities
in the last third, while the title and overview are at the top.  Chunking
with overlap ensures every section contributes to the similarity score.
The *best* score across all chunks is used (max-similarity strategy).
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass
from typing import TYPE_CHECKING

from jobsearch_rag.errors import ActionableError

if TYPE_CHECKING:
    from jobsearch_rag.rag.embedder import Embedder
    from jobsearch_rag.rag.store import VectorStore

logger = logging.getLogger(__name__)

# -- Chunking constants -----------------------------------------------------
# Overlap ensures no signal is lost at chunk boundaries (e.g. a comp range
# straddling two chunks).
_CHUNK_OVERLAP = 2_000


def _chunk_text(text: str, chunk_size: int, overlap: int = _CHUNK_OVERLAP) -> list[str]:
    """Split *text* into overlapping chunks of at most *chunk_size* chars.

    Short texts (≤ chunk_size) are returned as-is in a single-element list.
    Overlap ensures signals near chunk boundaries are not lost.
    """
    if len(text) <= chunk_size:
        return [text]

    chunks: list[str] = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        # Advance by (chunk_size - overlap), but at least 1 char to avoid infinite loop
        step = max(chunk_size - overlap, 1)
        start += step
    return chunks


# The disqualifier prompt sent as a *system* message.  The JD text is sent
# as the *user* message.
_DISQUALIFIER_SYSTEM_PROMPT = """\
You are a role-fit classifier for a senior/staff-level platform architect.
Analyse the following job description and decide whether it is structurally
unsuitable for a Principal/Staff Platform Architect candidate.

Disqualify if the role is:
- An individual-contributor coding role disguised with an "Architect" title
- Primarily SRE/on-call operations ownership
- A staffing-agency or vendor-chain posting
- Primarily full-stack web development

Respond ONLY with a JSON object (no markdown fences):
{"disqualified": true/false, "reason": "short explanation or null"}
"""


@dataclass
class ScoreResult:
    """Component scores for a single job listing."""

    fit_score: float
    archetype_score: float
    history_score: float
    disqualified: bool
    disqualifier_reason: str | None = None
    comp_score: float = 0.5
    negative_score: float = 0.0
    culture_score: float = 0.0

    @property
    def is_valid(self) -> bool:
        """All component scores are in [0.0, 1.0]."""
        return all(
            0.0 <= s <= 1.0
            for s in (
                self.fit_score,
                self.archetype_score,
                self.history_score,
                self.comp_score,
                self.negative_score,
                self.culture_score,
            )
        )


def _distance_to_score(distances: list[float]) -> float:
    """Convert a list of cosine distances to a single similarity score.

    ChromaDB returns *cosine distance* (1 - cosine_similarity).  We take
    the *minimum* distance (closest match) and clamp to [0.0, 1.0]:

        score = max(0.0, min(1.0, 1.0 - distance))
    """
    if not distances:
        return 0.0
    best = min(distances)
    return max(0.0, min(1.0, 1.0 - best))


class Scorer:
    """Computes semantic similarity scores and runs the LLM disqualifier.

    Parameters
    ----------
    store:
        A VectorStore with (at minimum) ``resume`` and ``role_archetypes``
        collections.  A ``decisions`` collection is optional — if absent or
        empty, the history score defaults to 0.0.
    embedder:
        An Embedder instance used to embed the JD text and to call the
        LLM disqualifier.
    disqualify_on_llm_flag:
        Whether ``score()`` should run the disqualifier prompt.  When False
        (e.g. for benchmarking), the disqualification step is skipped.
    """

    def __init__(
        self,
        *,
        store: VectorStore,
        embedder: Embedder,
        disqualify_on_llm_flag: bool = True,
    ) -> None:
        self._store = store
        self._embedder = embedder
        self._disqualify_on_llm_flag = disqualify_on_llm_flag
        self._cached_rejection_reasons: list[str] | None = None

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    async def score(self, jd_text: str) -> ScoreResult:
        """Score a job description against resume, archetypes, and decision history.

        For short JDs a single embedding is used.  Long JDs are split into
        overlapping chunks; each chunk is embedded and queried independently,
        and the **best** score across chunks is kept (max-similarity).  This
        ensures comp ranges and hands-on requirements buried in the tail of
        a JD contribute to the final score.

        Steps per chunk:

        1. Embed the chunk.
        2. Query the ``resume`` collection — best-match distance → ``fit_score``.
        3. Query the ``role_archetypes`` collection — → ``archetype_score``.
        4. Query the ``decisions`` collection (if present) — → ``history_score``.

        After all chunks:

        5. Optionally run the LLM disqualifier (on the full JD text).

        Raises ``ActionableError`` (INDEX) if the ``resume`` collection is
        empty or missing — the pipeline *must* index a resume before scoring.
        """
        chunks = _chunk_text(jd_text, chunk_size=self._embedder.MAX_EMBED_CHARS)
        if len(chunks) > 1:
            logger.debug(
                "JD text (%d chars) split into %d overlapping chunks for scoring",
                len(jd_text),
                len(chunks),
            )

        # Score each chunk and keep the best per-collection score.
        fit_score = 0.0
        archetype_score = 0.0
        history_score = 0.0
        negative_score = 0.0
        culture_score = 0.0

        for chunk in chunks:
            embedding = await self._embedder.embed(chunk)
            fit_score = max(fit_score, self._query_collection("resume", embedding))
            archetype_score = max(
                archetype_score,
                self._query_collection("role_archetypes", embedding),
            )
            history_score = max(
                history_score,
                self._query_collection_optional("decisions", embedding),
            )
            negative_score = max(
                negative_score,
                self._query_collection_optional("negative_signals", embedding),
            )
            culture_score = max(
                culture_score,
                self._query_collection_optional("global_positive_signals", embedding),
            )

        disqualified = False
        reason: str | None = None
        if self._disqualify_on_llm_flag:
            disqualified, reason = await self.disqualify(jd_text)

        return ScoreResult(
            fit_score=fit_score,
            archetype_score=archetype_score,
            history_score=history_score,
            disqualified=disqualified,
            disqualifier_reason=reason,
            negative_score=negative_score,
            culture_score=culture_score,
        )

    async def disqualify(self, jd_text: str) -> tuple[bool, str | None]:
        """Run the LLM disqualifier prompt. Returns ``(disqualified, reason)``.

        Past rejection reasons from "no" verdicts are injected into the
        system prompt so the LLM learns the operator's personal
        dealbreakers over time.  This makes decided reasons a *training
        signal* — e.g. if you previously rejected a role for "requires
        on-call rotation", future roles with on-call duties are flagged.

        If the LLM response is not valid JSON, the role is kept (safe
        default) and a warning is logged with the raw response so the
        prompt engineer can diagnose.
        """
        prompt = _DISQUALIFIER_SYSTEM_PROMPT
        rejection_reasons = self._get_rejection_reasons()
        if rejection_reasons:
            prompt += (
                "\n\nThe operator has also rejected roles for these personal reasons "
                "in the past.  Disqualify if this role clearly matches any of "
                "these patterns:\n"
            )
            for r in rejection_reasons:
                prompt += f"- {r}\n"
        raw = await self._embedder.classify(prompt + "\n\n" + jd_text)
        return self._parse_disqualifier_response(raw)

    # ------------------------------------------------------------------
    # Internals
    # ------------------------------------------------------------------

    def _query_collection(self, collection_name: str, embedding: list[float]) -> float:
        """Query a collection and return the best-match similarity score.

        Raises ``ActionableError.index`` if the collection is empty or
        does not exist.
        """
        count = self._store.collection_count(collection_name)
        if count == 0:
            msg = f"Collection '{collection_name}' is empty. Run the indexer before scoring."
            raise ActionableError.index(msg)

        n_results = min(count, 3)
        results = self._store.query(
            collection_name=collection_name,
            query_embedding=embedding,
            n_results=n_results,
        )
        distances: list[float] = results.get("distances", [[]])[0]
        return _distance_to_score(distances)

    def _query_collection_optional(self, collection_name: str, embedding: list[float]) -> float:
        """Query a collection, returning 0.0 if it's empty or missing."""
        try:
            count = self._store.collection_count(collection_name)
        except ActionableError:
            return 0.0
        if count == 0:
            return 0.0
        n_results = min(count, 3)
        results = self._store.query(
            collection_name=collection_name,
            query_embedding=embedding,
            n_results=n_results,
        )
        distances: list[float] = results.get("distances", [[]])[0]
        return _distance_to_score(distances)

    def _get_rejection_reasons(self) -> list[str]:
        """Collect non-empty reasons from 'no' verdicts in the decisions collection.

        Results are cached for the lifetime of the Scorer instance (one
        search run) to avoid repeated ChromaDB queries.
        """
        if self._cached_rejection_reasons is not None:
            return self._cached_rejection_reasons

        reasons: list[str] = []
        try:
            results = self._store.get_by_metadata(
                "decisions",
                where={"verdict": "no"},
                include=["metadatas"],
            )
            for meta in results.get("metadatas", []):
                if meta and meta.get("reason"):
                    reasons.append(str(meta["reason"]))
        except ActionableError:
            pass  # No decisions collection yet — normal on first run

        # Deduplicate while preserving order
        seen: set[str] = set()
        unique: list[str] = []
        for r in reasons:
            if r not in seen:
                seen.add(r)
                unique.append(r)

        self._cached_rejection_reasons = unique
        logger.debug(
            "Loaded %d rejection reason(s) for disqualifier augmentation",
            len(unique),
        )
        return unique

    @staticmethod
    def _parse_disqualifier_response(raw: str) -> tuple[bool, str | None]:
        """Parse the LLM disqualifier JSON response.

        Expected format::

            {"disqualified": true, "reason": "short explanation"}

        Falls back to ``(False, None)`` on any parse error — keeping the
        role is the safe default.
        """
        try:
            data = json.loads(raw)
            disqualified = bool(data.get("disqualified", False))
            reason = data.get("reason")
            if reason is not None:
                reason = str(reason)
                if reason.lower() == "null":
                    reason = None
            return disqualified, reason
        except (json.JSONDecodeError, AttributeError, TypeError):
            logger.warning("Malformed disqualifier response (keeping role): %s", raw)
            return False, None
